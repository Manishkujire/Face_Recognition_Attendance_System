{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f91fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc83d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8651be5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 40 classes.\n",
      "Found 40 images belonging to 40 classes.\n",
      "Found 80 images belonging to 40 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\minnu\\AppData\\Local\\Temp\\ipykernel_4832\\1013036527.py\", line 77, in <module>\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5581, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[64,41] labels_size=[64,40]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_5560]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 77\u001b[0m\n\u001b[0;32m     69\u001b[0m model_checkpoint_acc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath_acc,\n\u001b[0;32m     70\u001b[0m                                        save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m                                        monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     72\u001b[0m                                        mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     73\u001b[0m                                        save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m face_model_info \u001b[38;5;241m=\u001b[39m face_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     78\u001b[0m     train_generator,\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     81\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     82\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     83\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m     84\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m validation_generator\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m     85\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[csv_logger, model_checkpoint_val, model_checkpoint_acc]\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Save model structure in json file\u001b[39;00m\n\u001b[0;32m     89\u001b[0m model_json \u001b[38;5;241m=\u001b[39m face_model\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\minnu\\AppData\\Local\\Temp\\ipykernel_4832\\1013036527.py\", line 77, in <module>\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n\n  File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5581, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[64,41] labels_size=[64,40]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_5560]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create train generator\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\training',\n",
    "    target_size=(80, 70),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\validation',\n",
    "    target_size=(80, 70),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create test generator\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\testing',\n",
    "    target_size=(80, 70),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")\n",
    "class_indices_array = list(train_generator.class_indices.items())\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Assume you have 41 classes\n",
    "num_classes = 41\n",
    "\n",
    "# Create model structure\n",
    "face_model = Sequential()\n",
    "face_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80, 70, 1)))\n",
    "face_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "\n",
    "face_model.add(Flatten())\n",
    "face_model.add(Dense(512, activation='relu'))\n",
    "face_model.add(Dropout(0.5))\n",
    "face_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "face_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Define the callbacks\n",
    "output_dir = \"C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\checkpoint\"\n",
    "csv_logger = CSVLogger(os.path.join(output_dir, 'training.log'))\n",
    "\n",
    "checkpoint_filepath_val = os.path.join(output_dir, 'model_chkpt_val.h5')\n",
    "model_checkpoint_val = ModelCheckpoint(filepath=checkpoint_filepath_val,\n",
    "                                       save_weights_only=False,\n",
    "                                       monitor='val_accuracy',\n",
    "                                       mode='max',\n",
    "                                       save_best_only=True,\n",
    "                                       verbose=1)\n",
    "\n",
    "checkpoint_filepath_acc = os.path.join(output_dir, 'model_chkpt_acc.h5')\n",
    "model_checkpoint_acc = ModelCheckpoint(filepath=checkpoint_filepath_acc,\n",
    "                                       save_weights_only=False,\n",
    "                                       monitor='accuracy',\n",
    "                                       mode='max',\n",
    "                                       save_best_only=True,\n",
    "                                       verbose=1)\n",
    "\n",
    "# Train the model\n",
    "face_model_info = face_model.fit(\n",
    "    train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[csv_logger, model_checkpoint_val, model_checkpoint_acc]\n",
    ")\n",
    "\n",
    "# Save model structure in json file\n",
    "model_json = face_model.to_json()\n",
    "with open(\"face_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# Save class indices\n",
    "labels_json = json.dumps(dict(train_generator.class_indices))\n",
    "with open(\"labels_model.json\", \"w\") as json_file:\n",
    "    json_file.write(labels_json)\n",
    "    \n",
    "# Save trained model weights\n",
    "face_model.save_weights('face_model.h5')\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "604aac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 702ms/step\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'y_true' parameter of accuracy_score must be an array-like or a sparse matrix. Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(true_labels, predicted_labels)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Display classification report\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:201\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    199\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[1;32m--> 201\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    202\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'y_true' parameter of accuracy_score must be an array-like or a sparse matrix. Got 0 instead."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the model structure from the saved json file\n",
    "with open(\"face_model.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    face_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load the trained weights into the model\n",
    "# face_model.load_weights('face_model.h5')\n",
    "face_model.load_weights('D:\\\\Downloads\\\\Face-Recognition-master (1)\\\\Face-Recognition-master\\\\checkpoint\\\\model_chkpt_acc.h5')\n",
    "# Load the class indices\n",
    "with open(\"labels_model.json\", \"r\") as json_file:\n",
    "    class_indices = json.load(json_file)\n",
    "\n",
    "# Load the test generator for making predictions\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\testing',\n",
    "    target_size=(80, 70),\n",
    "    batch_size=32,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Ensure the order of predictions matches the order of images\n",
    ")\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = face_model.predict(test_generator)\n",
    "\n",
    "# Get the predicted labels and true labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# # Display the confusion matrix\n",
    "# conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# Display classification report\n",
    "class_report = classification_report(true_labels, predicted_labels, target_names=class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Visualization of predictions\n",
    "original_shape = (48, 48)\n",
    "\n",
    "# Create a graph to visualize the predictions\n",
    "fig, axes = plt.subplots(6, 4, figsize=(10, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # Load the image for display\n",
    "    img_path = os.path.join(test_generator.directory, test_generator.filenames[i])\n",
    "    img = image.load_img(img_path, target_size=(48, 48), color_mode=\"grayscale\")\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Reshape the flattened image to its original shape\n",
    "    ax.imshow(img_array.reshape(original_shape), cmap='gray')\n",
    "\n",
    "    # Get the predicted label\n",
    "    predicted_label_index = np.argmax(predictions[i])\n",
    "    predicted_label = list(class_indices.keys())[predicted_label_index]\n",
    "\n",
    "    # Get the true label\n",
    "    true_label = test_generator.classes[i]\n",
    "    \n",
    "    # Display the true and predicted labels with accuracy\n",
    "    ax.set_title(f'True: {list(class_indices.keys())[true_label]}\\nPredicted: {predicted_label}\\nAccuracy: {predictions[i][predicted_label_index]:.2f}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164b59f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 47ms/step\n",
      "[29 12 24  4 28 27  0  9  3 30  2 39 31 40 14 25 21 16 32 23 13 17 26 15\n",
      "  5 10 18 34  6  8 22 33 35 19  1 37 11  7 38 36 20]\n",
      "[29 12 24  4 28 27  0  9  3 30  2 39 31 40 14 25 21 16 32 23 13 17 26 15\n",
      "  5 10 18 34  6  8 22 33 35 19  1 37 11  7 38 36 20]\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def test_accuracy(test_generator, face_model):\n",
    "    try:\n",
    "        # Use the generator to load the test dataset\n",
    "        test_images, test_labels = test_generator.next()\n",
    "\n",
    "#         test_images = test_images.astype('float32') / 255.0\n",
    "#         print(test_generator[0][0][6])\n",
    "# #         Use the trained model to predict labels for the test set\n",
    "#         with open(\"face_model.json\", \"r\") as json_file:\n",
    "#             loaded_model_json = json_file.read()\n",
    "#             face_model = model_from_json(loaded_model_json)\n",
    "#         face_model.load_weights('face_model.h5')\n",
    "\n",
    "#         face_model.load_weights('D:\\\\Downloads\\\\Face-Recognition-master (1)\\\\Face-Recognition-master\\\\checkpoint\\\\model_chkpt_val.h5')\n",
    "        \n",
    "        predictions = face_model.predict(test_images)\n",
    "#         print(predictions)\n",
    "        # Convert predictions to class labels\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        print(predicted_labels)\n",
    "        # Compare predicted labels with true labels\n",
    "        true_labels = np.argmax(test_labels, axis=1)\n",
    "        print(true_labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(predicted_labels == true_labels)\n",
    "#         print(test_labels)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "        return None\n",
    "\n",
    "# Calculate and print test accuracy\n",
    "test_accuracy_value= test_accuracy(test_generator, face_model)\n",
    "\n",
    "if test_accuracy_value is not None:\n",
    "    print(f'Test Accuracy: {test_accuracy_value * 100:.2f}%')\n",
    "else:\n",
    "    print('Error calculating test accuracy.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18127d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's41', 's5', 's6', 's7', 's8', 's9']\n",
      "4\n",
      "s13\n",
      "Prediction Accuracy: 98.62%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "# Load JSON data from the file\n",
    "with open(\"labels_model.json\", \"r\") as json_file:\n",
    "    labels_json = json_file.read()\n",
    "\n",
    "# Deserialize JSON to a dictionary\n",
    "class_indices_dict = json.loads(labels_json)\n",
    "\n",
    "# Convert dictionary values to an array\n",
    "class_indices_array = list(class_indices_dict)\n",
    "# # Load the model structure from the saved json file\n",
    "# with open(\"C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\face_model.json\", \"r\") as json_file:\n",
    "#     loaded_model_json = json_file.read()\n",
    "#     face_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load the trained weights into the model\n",
    "# face_model.load_weights('C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\checkpoint\\\\model_chkpt_acc.h5')\n",
    "# face_model.load_weights('face_model.h5')\n",
    "\n",
    "# Load the image for detection\n",
    "# img_path = r\"C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\testing\\\\s26\\\\251_26.jpg\"\n",
    "img_path = r\"D:\\\\Downloads\\\\larine.jpg\"\n",
    "img = image.load_img(img_path, target_size=(80, 70), color_mode=\"grayscale\")\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "\n",
    "# Make prediction\n",
    "face_prediction = face_model.predict(img_array)\n",
    "# print(face_prediction)\n",
    "# print(emotion_prediction[0][23]*100)\n",
    "\n",
    "# Get the predicted emotion label\n",
    "predicted_label_index = np.argmax(face_prediction)\n",
    "predicted_label = class_indices_array[predicted_label_index]\n",
    "accuracy_value = float(face_prediction[0][predicted_label_index] * 100)\n",
    "print(class_indices_array)\n",
    "print(predicted_label_index)\n",
    "print(predicted_label)\n",
    "\n",
    "# Display the image with the predicted label\n",
    "img = cv2.imread(img_path)\n",
    "cv2.putText(img, f\"Predicted: {predicted_label}\", (1, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "# Extract the numerical value of accuracy\n",
    "print(f\"Prediction Accuracy: {accuracy_value:.2f}%\")\n",
    "\n",
    "cv2.imshow('Image Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b2c0e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d084e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d33002",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_json = json.dumps(train_generator.class_indices)\n",
    "with open(\"labels_model.json\", \"w\") as json_file:\n",
    "    json_file.write(labels_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c79354",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f80f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 80, 70, 1), found shape=(None, 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 44\u001b[0m\n\u001b[0;32m     36\u001b[0m img_array \u001b[38;5;241m=\u001b[39m face_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.3\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# img = image.load_img(img_path, target_size=(80, 70), color_mode=\"grayscale\")\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# img_array = image.img_to_array(img)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# img_array = np.expand_dims(img_array, axis=0)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# img_array /= 255.0\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m face_prediction \u001b[38;5;241m=\u001b[39m face_model\u001b[38;5;241m.\u001b[39mpredict(img_array)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(face_prediction)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# print(emotion_prediction[0][23]*100)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Get the predicted emotion label\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2f11ir79.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\minnu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 80, 70, 1), found shape=(None, 4)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "# # Load JSON data from the file\n",
    "# with open(\"labels_model.json\", \"r\") as json_file:\n",
    "#     labels_json = json_file.read()\n",
    "\n",
    "# # Deserialize JSON to a dictionary\n",
    "# class_indices_dict = json.loads(labels_json)\n",
    "\n",
    "# # Convert dictionary values to an array\n",
    "# class_indices_array = list(class_indices_dict)\n",
    "\n",
    "# # Load the model structure from the saved json file\n",
    "# with open(\"C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\face_model.json\", \"r\") as json_file:\n",
    "#     loaded_model_json = json_file.read()\n",
    "#     face_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# # Load the trained weights into the model\n",
    "# face_model.load_weights('C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\checkpoint\\\\model_chkpt_acc.h5')\n",
    "# # face_model.load_weights('face_model.h5')\n",
    "\n",
    "# Load the image for detection\n",
    "# img_path = r\"D:\\\\Downloads\\\\Face-Recognition-master (1)\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\testing\\\\s26\\\\251_26.jpg\"\n",
    "img_path = r\"D:\\\\Downloads\\\\larine.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "    \n",
    "    # Load the pre-trained face cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "img_array = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "# img = image.load_img(img_path, target_size=(80, 70), color_mode=\"grayscale\")\n",
    "# img_array = image.img_to_array(img)\n",
    "# img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.0\n",
    "\n",
    "# Make prediction\n",
    "face_prediction = face_model.predict(img_array)\n",
    "print(face_prediction)\n",
    "# print(emotion_prediction[0][23]*100)\n",
    "\n",
    "# Get the predicted emotion label\n",
    "predicted_label_index = np.argmax(face_prediction)\n",
    "predicted_label = class_indices_array[predicted_label_index]\n",
    "accuracy_value = float(face_prediction[0][predicted_label_index] * 100)\n",
    "print(class_indices_array)\n",
    "print(predicted_label_index)\n",
    "print(predicted_label)\n",
    "\n",
    "# Display the image with the predicted label\n",
    "img = cv2.imread(img_path)\n",
    "cv2.putText(img, f\"Predicted: {predicted_label}\", (1, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "# Extract the numerical value of accuracy\n",
    "print(f\"Prediction Accuracy: {accuracy_value:.2f}%\")\n",
    "\n",
    "cv2.imshow('Image Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec904a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def detect_and_crop_faces(image_path, save_dir):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Load the pre-trained face cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "    # Create the save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Crop and save each detected face\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        # Extract the face region\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize the face image to 80x70 pixels\n",
    "        face_roi = cv2.resize(face_roi, (70, 80))\n",
    "        \n",
    "        # Save the cropped face\n",
    "        save_path = os.path.join(save_dir, f\"cropped_face_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, face_roi)\n",
    "        \n",
    "        # Draw a rectangle around the detected face in the original image\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the original image with rectangles around detected faces\n",
    "    cv2.imshow('Detected Faces', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\Datasets\\\\Faces\\\\testing\\\\s26\\\\251_26.jpg\"\n",
    "image_path = r\"D:\\\\Downloads\\\\larine.jpg\"\n",
    "\n",
    "save_directory = r\"C:\\\\Users\\\\minnu\\\\Downloads\\\\Face-Recognition\\\\Face-Recognition-master\\\\cropped_faces\"\n",
    "\n",
    "detect_and_crop_faces(image_path, save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9e429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
